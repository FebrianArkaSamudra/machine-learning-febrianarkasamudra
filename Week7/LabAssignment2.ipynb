{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423c68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import faiss\n",
    "from annoy import AnnoyIndex\n",
    "import hnswlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c08f595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('songs_with_attributes_and_lyrics.csv')  # Change the path according to your file location\n",
    "\n",
    "# Select feature columns for similarity search\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', \n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "X = df[features].values\n",
    "\n",
    "# Standardize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Set parameters\n",
    "k = 10  # number of nearest neighbors to search\n",
    "n_samples = X_scaled.shape[0]  # total number of samples\n",
    "dim = X_scaled.shape[1]        # number of features (dimensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cdb6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('songs_with_attributes_and_lyrics.csv')  # Update the path based on the file location\n",
    "\n",
    "# Select relevant audio features\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', \n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "X = df[features].values\n",
    "\n",
    "# Standardize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define parameters\n",
    "k = 10                       # Number of nearest neighbors\n",
    "n_samples = X_scaled.shape[0]  # Total number of samples\n",
    "dim = X_scaled.shape[1]        # Number of feature dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c2d22be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Exact Nearest Neighbors...\n",
      "Exact NN time: 0.0374 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1. Exact Nearest Neighbors\n",
    "print(\"Running Exact Nearest Neighbors...\")\n",
    "\n",
    "# Measure execution time\n",
    "start = time.time()\n",
    "\n",
    "# Initialize and fit the brute-force NN model using Euclidean distance\n",
    "nn_model = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "nn_model.fit(X_scaled)\n",
    "\n",
    "# Find nearest neighbors for the first sample\n",
    "distances, indices = nn_model.kneighbors(X_scaled[:1])\n",
    "\n",
    "# Calculate total time taken\n",
    "exact_time = time.time() - start\n",
    "print(f\"Exact NN time: {exact_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9add8711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Annoy...\n",
      "Annoy time: 2.6699 seconds\n"
     ]
    }
   ],
   "source": [
    "# 2. Annoy\n",
    "print(\"\\nRunning Annoy...\")\n",
    "\n",
    "# Initialize Annoy index with Euclidean distance\n",
    "annoy_index = AnnoyIndex(dim, 'euclidean')\n",
    "\n",
    "# Add all data points to the index\n",
    "for i in range(n_samples):\n",
    "    annoy_index.add_item(i, X_scaled[i])\n",
    "\n",
    "# Measure build and query time\n",
    "start = time.time()\n",
    "annoy_index.build(10)  # Build the index with 10 trees\n",
    "neighbors = annoy_index.get_nns_by_item(0, k)  # Query for k nearest neighbors of the first item\n",
    "annoy_time = time.time() - start\n",
    "\n",
    "print(f\"Annoy time: {annoy_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8b272c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running FAISS...\n",
      "FAISS time: 0.0424 seconds\n"
     ]
    }
   ],
   "source": [
    "# 3. FAISS\n",
    "print(\"\\nRunning FAISS...\")\n",
    "\n",
    "# Initialize FAISS index using L2 (Euclidean) distance\n",
    "index_faiss = faiss.IndexFlatL2(dim)\n",
    "\n",
    "# Measure the time to add data and perform the search\n",
    "start = time.time()\n",
    "index_faiss.add(X_scaled.astype('float32'))  # Add the data to the index\n",
    "D, I = index_faiss.search(X_scaled[:1].astype('float32'), k)  # Search for k nearest neighbors of the first item\n",
    "faiss_time = time.time() - start\n",
    "\n",
    "print(f\"FAISS time: {faiss_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45884733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running HNSWLIB...\n",
      "HNSW time: 0.0005 seconds\n"
     ]
    }
   ],
   "source": [
    "# 4. HNSWLIB\n",
    "print(\"\\nRunning HNSWLIB...\")\n",
    "\n",
    "# Initialize HNSW index with L2 (Euclidean) distance\n",
    "p = hnswlib.Index(space='l2', dim=dim)\n",
    "\n",
    "# Create the index with construction parameters\n",
    "p.init_index(max_elements=n_samples, ef_construction=100, M=16)\n",
    "\n",
    "# Add all data points to the index\n",
    "p.add_items(X_scaled)\n",
    "\n",
    "# Measure query time for the first item\n",
    "start = time.time()\n",
    "labels, distances = p.knn_query(X_scaled[:1], k=k)\n",
    "hnsw_time = time.time() - start\n",
    "\n",
    "print(f\"HNSW time: {hnsw_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62614603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Performance Comparison ===\n",
      "     Method  Execution Time (s)\n",
      "0  Exact NN            0.037416\n",
      "1     Annoy            2.669936\n",
      "2     FAISS            0.042378\n",
      "3   HNSWLIB            0.000490\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to store the execution times of each method\n",
    "results = pd.DataFrame({\n",
    "    'Method': ['Exact NN', 'Annoy', 'FAISS', 'HNSWLIB'],\n",
    "    'Execution Time (s)': [exact_time, annoy_time, faiss_time, hnsw_time]\n",
    "})\n",
    "\n",
    "# Display the performance comparison\n",
    "print(\"\\n=== Performance Comparison ===\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26373867",
   "metadata": {},
   "source": [
    "The performance comparison revealed that HNSWLIB delivered the fastest execution time, completing the nearest neighbor search in just 0.001 seconds. FAISS and Exact Nearest Neighbors produced similar outcomes, with FAISS performing slightly slower than the exact method but still maintaining good efficiency. On the other hand, ANNOY was noticeably slower, taking over 5 seconds to complete the same task. These findings highlight HNSWLIB as the most efficient option in terms of speed and scalability, making it well-suited for large-scale or real-time similarity search tasks, whereas ANNOY is less suitable for high-performance demands."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-febrianarkasamudra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
